> After the model predictions, there will be several misclassified
> pixels on the the classified imagery. These need to removed through
> the application of some post-processing rationale. This step is
> important for improving the accuracy of the maps.

Steps like using a sieve function to remove lone misclassified pixels (one or few pixels) is a way to do some post-processing correction of the classifier imagery. However, as I have noted in the current study, such functions can remove correctly classified pixels, such as those of water in small mountain streams. I have developed an alternate method for post-classification misclassified pixel removal using a 'probability landscape' approach. 

I use the training data for the classification and data from the DEM (such as slope, aspect, roughedness etc) to create a landscape where a respective class could potentialy occur. Then, all pixels classified as such outside of this probability landscape is removed. This method works best for those classes which have distinct patterns of occurrence such as water, snow, agriculture etc, as they are not spread across the entire landscape or they are spread in a predictable manner. It will also work to slightly clean up the classes which occur widely across the landscape such as dense canopy forests.

I am including two workflows here. The first one will give you an understanding of each of the steps involved in details, and includes the production of publication-ready plots. This workflow is largely for understanding the steps involved, and therefore has several repetitive tasks. And every model name will have to be manually inputted and then run separately.The second workflow removes all the optional tasks like plot creation and other optional steps and provides a fully optimised workflow to handle multiple models located within a devices (in my case, I had 114 models to be post-processed, split across desktops containing GNU/Linux and Windows OS).  

<br>

#### Table of contents

- [Workflow 1 - Elaborate and unoptimised](#workflow-1---elaborate-and-unoptimised)
- [Workflow 2 - Minimalist and optimised](#workflow-2---minimalist-and-optimised)

<br>

## Workflow 1 - Elaborate and unoptimised

The following is the R script for carrying out the same:

```
#Set the working directory:
#ctrl+Shift+H or setwd("D:/GIS/LULC-SIANG/classified_imagery")

#Check the current working directory (optional)
getwd()

#Uncomment (remove #) the following line and Inssall the packages 'raster' and 
#'sp' if not already installed. Note that you may have to install or update some
#dependencies if the installation is not working. Check the errors/warnings. 
#install.packages(c("raster","sf"))

#Load the 'raster' and 'sf' package:
library(raster)
library(sf)

#SKIP THE NEXT THREE STEP STEPS IF YOU ARE STARTING WITH A KML FILE

# Add the  kmz file containing the training data to the "classified_imagery" folder
#list the kmz files in the folder (should be just the one file with the training data)
kmz <- list.files(pattern="*.kmz", full.names=FALSE)

# Create temporary directory
temp_dir <- tempdir()

# Unzip KMZ (this will extract the KML file inside
unzip(kmz, exdir = temp_dir)

# Find the extracted KML file (or just the kml file if you're starting directly from kml)
kml_file <- list.files(temp_dir, pattern = "\\.kml$", full.names = TRUE)

# Read the KML file with sf
data <- st_read(kml_file)

#Output in Linux
# Reading layer `2024_updated' from data source `/tmp/Rtmpw7uo9z/doc.kml' using driver `LIBKML'
# Simple feature collection with 2358 features and 11 fields
# Geometry type: POINT
# Dimension:     XYZ
# Bounding box:  xmin: 93.99069 ymin: 27.56451 xmax: 95.56589 ymax: 29.33588
# z_range:       zmin: 0 zmax: 0
# Geodetic CRS:  WGS 84

#Output in Windows:
# Reading layer `2024_updated' from data source 
#   `C:\Users\GIS\AppData\Local\Temp\RtmpQPSSTT\doc.kml' using driver `KML'
# Simple feature collection with 2358 features and 2 fields
# Geometry type: POINT
# Dimension:     XYZ
# Bounding box:  xmin: 93.99069 ymin: 27.56451 xmax: 95.56589 ymax: 29.33588
# z_range:       zmin: 0 zmax: 0
# Geodetic CRS:  WGS 84

# Get coordinates
coordinates <- st_coordinates(data)
class(coordinates)

#(OPTIONAL) Plot
plot(coordinates)

#(OPTIONAL) Save the above if you want:
png("coordinates.png")
```
Output:
![enter image description here][1]
```
#(OPTIONAL) Check a few lines (6) of the 'data':
head(data)

#Change working directory to where the DEM to be used is located (or else, move the DEM to the current working directory): setwd("D:/GIS/LULC-SIANG/DEM")

#Load the virtual raster layer:
dem <- raster("alos.vrt")

#Extract DEM data for the points:
sp <- extract(dem, SpatialPoints(coordinates), sp = T)

#(OPTIONAL) View the first few rows
head(sp@coords)
head(data$Name)
head(sp@data$alos)

# Create a data frame with Name, coordinates (X,Y), and elevation (alos)
result_df <- data.frame(
  Name = data$Name,
  Longitude = sp@coords[, "X"],
  Latitude = sp@coords[, "Y"],
  Elevation = sp@data$alos
)

#(OPTIONAL) View the first few rows
head(result_df)

#OR you can use this instead:
  
# library(dplyr)  
# library(tibble) 
# 
# result_df <- tibble(
#   Name = data$Name,
#   Longitude = sp@coords[, "X"],
#   Latitude = sp@coords[, "Y"],
#   Elevation = sp@data$alos
# ) %>% 
#   as.data.frame()

#Create slope and aspect objects
aspect <- terrain(dem,opt='aspect',unit='degrees', neighbours = 8)
class(aspect)
#Neighbours = 8 best for rough surfaces Horn (1981) like Siang 
slope <- terrain(dem,opt='slope',unit='degrees',  neighbours = 8)
#The above steps can be done for all the options available under the terrain 
#function in the raster package:
TPI <- terrain(dem,opt='TPI') 
TRI <- terrain(dem,opt='TRI')
roughness <- terrain(dem,opt='roughness')
flowdir <- terrain(dem,opt='flowdir')

#Extract aspect data:
sp2 <- extract(aspect, SpatialPoints(coordinates), sp = T)
#Extract slope data:
sp3 <- extract(slope, SpatialPoints(coordinates), sp = T)
#Extract Topographic Position Index for the respective coordinates:
sp4 <- extract(TPI, SpatialPoints(coordinates), sp = T)
#Extract Terrain Ruggedness Index:
sp5 <- extract(TRI, SpatialPoints(coordinates), sp = T)
#Extract roughness:
sp6 <- extract(roughness, SpatialPoints(coordinates), sp = T)
#Extract Terrain Ruggedness Index:
sp7 <- extract(flowdir, SpatialPoints(coordinates), sp = T)

#Add the slope, aspect, TPI, TRI, roughness and flowdir information for the corresponding 
#coordinates in result_df after loading the dplyr package:
library(dplyr)

result_df <- result_df %>% 
  mutate(Aspect = sp2@data$aspect,
         Slope = sp3@data$slope,
         TPI = sp4@data$tpi,
         TRI = sp5@data$tri,
         Roughness = sp6@data$roughness,
         Flowdir = sp7@data$flowdir)

#(OPTIONAL) View the structure of 'result_df' dataframe
str(result_df) 

#Import the shapefiles (should have it in the working directory):
shp <- read_sf("study_area/study_area.shp") 
#(OPTIONAL) Plot the shapefile
plot(shp)
#(OPTIONAL) check the class of the shapefile
class(shp)

#Load the 'terra' package:
library(terra)

#for aspect
# Convert to terra format (handles 3D data better)
aspect_terra <- rast(aspect)  # Convert raster
shp_vect <- vect(shp)         # Convert sf - maintains Z dimension if present

# Check and match CRS
if (!same.crs(aspect_terra, shp_vect)) {
  shp_vect <- project(shp_vect, aspect_terra)
}

# Perform mask (terra handles 3D vector data)
asp <- mask(aspect_terra, shp_vect)
class(asp)
# [1] "SpatRaster"
# attr(,"package")
# [1] "terra"

#Remove the object 'aspect_terra' as it's not needed anymore:
rm(aspect_terra)

----------OPTIONAL (START) --------------

#Write the aspect raster:
writeRaster(
  asp,
  filename = "aspect.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE       #Overwrites another file with the name 'aspect.tif' if found within the same folder
)

#View and plot the 'asp' object:
asp
plot(asp)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(asp, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(asp, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("aspect.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                                  # Create plot
dev.off()                                     # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][2]

```
#For slope
# Convert to terra format (handles 3D data better)
slope_terra <- rast(slope)  # Convert raster

# Check and match CRS
if (!same.crs(slope_terra, shp_vect)) {
  shp_vect <- project(shp_vect, slope_terra)
}

# Perform mask (terra handles 3D vector data)
slp <- mask(slope_terra, shp_vect)
#(OPTIONAL) Check the class
class(slp)

#Remove the object 'slope_terra' as it's not needed anymore:
rm(slope_terra)

----------OPTIONAL (START) --------------

#Write the slope raster:
writeRaster(
  slp,
  filename = "slope.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

slp
plot(slp)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(slp, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(slp, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("slope.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                                 # Create plot
dev.off()                                    # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][3]

```
##TPI

# Convert to terra format (handles 3D data better)
TPI_terra <- rast(TPI)  # Convert raster

# Check and match CRS
if (!same.crs(TPI_terra, shp_vect)) {
  shp_vect <- project(shp_vect, TPI_terra)
}

# Perform mask (terra handles 3D vector data)
cTPI <- mask(TPI_terra, shp_vect)
#(OPTIONAL) Check the class
class(cTPI)

#Remove the object 'TPI_terra' as it's not needed anymore:
rm(TPI_terra)

----------OPTIONAL (START) --------------

#Write the TPI raster:
writeRaster(
  cTPI,
  filename = "TPI.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

cTPI
plot(cTPI)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(cTPI, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(cTPI, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("TPI.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                               # Create plot
dev.off()                                  # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][4]
```
##For TRI

# Convert to terra format (handles 3D data better)
TRI_terra <- rast(TRI)  # Convert raster

# Check and match CRS
if (!same.crs(TRI_terra, shp_vect)) {
  shp_vect <- project(shp_vect, TRI_terra)
}

# Perform mask (terra handles 3D vector data)
cTRI <- mask(TRI_terra, shp_vect)
#(OPTIONAL) Check the class
class(cTRI)

#Remove the object 'TRI_terra' as it's not needed anymore:
rm(TRI_terra)

----------OPTIONAL (START) --------------

#Write the TRI raster:
writeRaster(
  cTRI,
  filename = "TRI.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

cTRI
plot(cTRI)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(cTRI, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(cTRI, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("TRI.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                               # Create plot
dev.off()                                  # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][5]

```
##For roughness
# Convert to terra format (handles 3D data better)
rough_terra <- rast(roughness)  # Convert raster

# Check and match CRS
if (!same.crs(rough_terra, shp_vect)) {
  shp_vect <- project(shp_vect, rough_terra)
}

# Perform mask (terra handles 3D vector data)
rough <- mask(rough_terra, shp_vect)
#(OPTIONAL) Check the class
class(rough)

#Remove the object 'rough_terra' as it's not needed anymore:
rm(rough_terra)

----------OPTIONAL (START) --------------
#Write the rough raster:
writeRaster(
  rough,
  filename = "roughness.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

rough
plot(rough)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(rough, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(rough, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("roughness.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                                     # Create plot
dev.off()                                         # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][6]
```
##For flowdir
# Convert to terra format (handles 3D data better)
fldr_terra <- rast(flowdir)  # Convert raster

# Check and match CRS
if (!same.crs(fldr_terra, shp_vect)) {
  shp_vect <- project(shp_vect, fldr_terra)
}

# Perform mask (terra handles 3D vector data)
fldr <- mask(fldr_terra, shp_vect)
#(OPTIONAL) Check the class
class(fldr)

#Remove the object 'fldr_terra' as it's not needed anymore:
rm(fldr_terra)

----------OPTIONAL (START) --------------
#Write the fldr raster:
writeRaster(
  fldr,
  filename = "flowdir.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

fldr
plot(fldr)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(fldr, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(fldr, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("flowdir.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                                   # Create plot
dev.off()                                      # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][7]
```
#Also create the masked elevation raster:
# Convert to terra format (handles 3D data better)
dem_terra <- rast(dem)  # Convert raster

# Check and match CRS
if (!same.crs(dem_terra, shp_vect)) {
  shp_vect <- project(shp_vect, dem_terra)
}

# Perform mask (terra handles 3D vector data)
elev <- mask(dem_terra, shp_vect)
#(OPTIONAL) Check the class
class(elev)
# [1] "SpatRaster"
# attr(,"package")
# [1] "terra"

#Remove the object 'dem_terra' as it's not needed anymore:
rm(dem_terra)

----------OPTIONAL (START) --------------

#Write the elevation raster:
writeRaster(
  elev,
  filename = "elevation.tif",
  datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
  NAflag = -9999,        # Value for missing data
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE
)

elev
# class       : SpatRaster 
# dimensions  : 10800, 10800, 1  (nrow, ncol, nlyr)
# resolution  : 0.0002777778, 0.0002777778  (x, y)
# extent      : 93, 96, 27, 30  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=longlat +datum=WGS84 +no_defs 
# source(s)   : memory
# varname     : alos 
# name        : alos 
# min value   :   89 
# max value   : 5186 
plot(elev)

#In the next step, select the extent by clicking on two vertices of the map
#(zooming in):
zoom_extent <- zoom(elev, drawExtent())
#Crop to the extent selected in the previous step:
zoomed <- crop(elev, zoom_extent)
plot(zoomed)
#Save the zoomed in raster
png("elevation.png", width = 800, height = 600)  # Start image capture
plot(zoomed)                                     # Create plot
dev.off()                                            # Save image

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][22]
```
#Remove unwanted (large) objects:
rm(aspect, flowdir, roughness, slope, TPI, TRI)
#and other objects:
rm(sp,sp2,sp3,sp4,sp5,sp6,sp7)

----------OPTIONAL (START) --------------
#Many sections starting here are optional

#Check the max and min of all the relevant columns:
summary(result_df)

# Longitude        Latitude       Elevation          Aspect          Slope          Roughness     
# Min.   :93.99   Min.   :27.56   Min.   : 120.0   Min.   :  0.0   Min.   : 0.000   Min.   :  0.00  
# 1st Qu.:94.59   1st Qu.:28.00   1st Qu.: 323.2   1st Qu.:117.1   1st Qu.: 4.537   1st Qu.:  7.00  
# Median :94.90   Median :28.34   Median : 691.5   Median :180.4   Median :18.939   Median : 27.00  
# Mean   :94.88   Mean   :28.38   Mean   :1325.3   Mean   :184.6   Mean   :20.137   Mean   : 31.29  
# 3rd Qu.:95.21   3rd Qu.:28.75   3rd Qu.:2140.2   3rd Qu.:256.0   3rd Qu.:32.413   3rd Qu.: 47.75  
# Max.   :95.57   Max.   :29.34   Max.   :4813.0   Max.   :360.0   Max.   :69.185   Max.   :179.00 

# Flowdir           TPI                TRI        
# Min.   :  1.0   Min.   :-24.0000   Min.   : 0.000  
# 1st Qu.:  1.0   1st Qu.: -1.6250   1st Qu.: 2.375  
# Median : 16.0   Median : -0.1250   Median : 8.125  
# Mean   : 14.7   Mean   : -0.4417   Mean   : 9.639  
# 3rd Qu.: 16.0   3rd Qu.:  1.0000   3rd Qu.:14.500  
# Max.   :128.0   Max.   : 16.8750   Max.   :63.125  

#Plot the values for classes together:

# Select the columns of interest
cols_to_plot <- c("Elevation", "Aspect", "Slope", "Roughness", "Flowdir", "TPI", "TRI")

# Convert to long format for faceting
df_long <- pivot_longer(result_df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

#Load ggplot2 package:
library(ggplot2)

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms.png",        # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][8]
```
# Split the dataframe by the 'Name' column to get the different classes:
split_df_list <- result_df %>% group_split(Name)

----------OPTIONAL (START) --------------
str(split_df_list)
head(result_df)

#Alluvial Grasslands:
split_df_list[[1]]
summary(split_df_list[[1]])

#Load the necessary packages:
library(ggplot2)
library(tidyr)

#Plot variables for alluvial grasslands:
# Extract the dataframe from the list
df <- split_df_list[[1]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for alluvial grassland", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_alluvial_grasslands.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][9]
```
#Active jhum:
split_df_list[[2]]
summary(split_df_list[[2]])

#Plot variables for active jhum:
# Extract the dataframe from the list
df <- split_df_list[[2]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for active jhum", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_active_jhum.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][10]
```
#Bamboo:
split_df_list[[3]]
summary(split_df_list[[3]])

#Plot variables for bamboo:
# Extract the dataframe from the list
df <- split_df_list[[3]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for bamboo", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_bamboo.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][11]
```
#Built-up:
split_df_list[[4]]
summary(split_df_list[[4]])

# Extract the dataframe from the list
df <- split_df_list[[4]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for built-up", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_built-up.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][12]
```
#Cash-crops:
split_df_list[[5]]
summary(split_df_list[[5]])

# Extract the dataframe from the list
df <- split_df_list[[5]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for cash-crops", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_cash-crops.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
![enter image description here][13]
```
#Montane grassland:
split_df_list[[6]]
summary(split_df_list[[6]])

# Extract the dataframe from the list
df <- split_df_list[[6]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for montane grassland", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_montane-grassland.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][14]
```
#Open canopy:
split_df_list[[7]]
summary(split_df_list[[7]])

# Extract the dataframe from the list
df <- split_df_list[[7]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for open canopy", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_open-canopy.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][15]
```
#Shadow:
split_df_list[[8]]
summary(split_df_list[[8]])

# Extract the dataframe from the list
df <- split_df_list[[8]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for shadow", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_shadow.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][16]
```
#Snow:
split_df_list[[9]]
summary(split_df_list[[9]])

# Extract the dataframe from the list
df <- split_df_list[[9]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for snow", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_snow.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][17]
```
#Bare surface:
split_df_list[[10]]
summary(split_df_list[[10]])

# Extract the dataframe from the list
df <- split_df_list[[10]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for bare surface", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_bare-surface.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][18]
```
#Dense canopy:
split_df_list[[11]]
summary(split_df_list[[11]])

# Extract the dataframe from the list
df <- split_df_list[[11]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for dense canopy", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_dense-canopy.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][19]
```
#Water:
split_df_list[[12]]
summary(split_df_list[[12]])

# Extract the dataframe from the list
df <- split_df_list[[12]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for water", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_water.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)
```
Output:
![enter image description here][20]
```
#Wet rice cultivation:
split_df_list[[13]]
summary(split_df_list[[13]])

# Extract the dataframe from the list
df <- split_df_list[[13]]

# Convert to long format for faceting
df_long <- pivot_longer(df, cols = all_of(cols_to_plot), names_to = "Variable", values_to = "Value")

# Plot faceted histograms
plot <- ggplot(df_long, aes(x = Value)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black") +
  facet_wrap(~Variable, scales = "free") +
  labs(title = "Histograms of terrain variables for wet rice cultivation", x = "Value", y = "Frequency") +
  scale_y_continuous(n.breaks = 10)  +
  scale_x_continuous(n.breaks = 10)  +
  theme_minimal()
plot

# Save as PNG
ggsave(
  filename = "terrain_histograms_wet-rice-cultivation.png",   # Output filename
  plot = plot,                                # Plot object
  device = "png",                             # File format
  dpi = 300,                                  # Resolution (300 DPI)
  width = 12,                                 # Width in inches
  height = 7,                                 # Height in inches
)

----------OPTIONAL (END) --------------
```
Output:
![enter image description here][21]
```
#Find the difference between maximum and minimum between different classes and
#combined histograms:

----------OPTIONAL (START) --------------

# Step 1: Calculate Global Max/Min (from result_df)
# First, compute the overall max and min for each variable across all classes:

global_stats_1 <- result_df %>%
  summarise(across(c(Elevation, Aspect, Slope, Roughness, Flowdir, TPI, TRI),
                   list(
                     max = ~max(., na.rm = TRUE),  # Using formula syntax
                     min = ~min(., na.rm = TRUE)   # or anonymous function
                   )))

str(global_stats_1)

----------OPTIONAL (END) --------------

#Note that the above object 'global_stats_1' will only give values for which there are corresponding
#training data. This may not be the true max and min. So, get the true global_stats:

global_stats <- as.data.frame(cbind(
                     Elevation_max = elev@cpp[["range_max"]],
                     Elevation_min = elev@cpp[["range_min"]],
                     Aspect_max = asp@cpp[["range_max"]],
                     Aspect_min = asp@cpp[["range_min"]],
                     Slope_max = slp@cpp[["range_max"]],
                     Slope_min = slp@cpp[["range_min"]],
                     Roughness_max = rough@cpp[["range_max"]],
                     Roughness_min = rough@cpp[["range_min"]],
                     Flowdir_max = fldr@cpp[["range_max"]],
                     Flowdir_min = fldr@cpp[["range_min"]],
                     TPI_max = cTPI@cpp[["range_max"]],
                     TPI_min = cTPI@cpp[["range_min"]],
                     TRI_max = cTRI@cpp[["range_max"]],
                     TRI_min = cTRI@cpp[["range_min"]]
                   ))
                   
#Note that the word 'pntr' may need to be changed to 'cpp' if using an earlier
#version of the terra package(?) (the above operation will throw this error otherwise:
# Error in h(simpleError(msg, call)) : error in evaluating the argument 'x' in 
#selecting a method for function 'as.data.frame': no slot of name "cpp" for this 
#object of class "SpatRaster"
#You can check by looking at one of the above objects. For example, check under 
#which main heading "range_max" and "range_min" of the object 'elev' is under:
View(elev)

#(OPTIONAL) View the structure of the above dataframe:
str(global_stats)
# 'data.frame':	1 obs. of  14 variables:
#   $ Elevation_max: num 5186
# $ Elevation_min: num 89
# $ Aspect_max   : num 360
# $ Aspect_min   : num 0
# $ Slope_max    : num 81.1
# $ Slope_min    : num 0
# $ Roughness_max: num 432
# $ Roughness_min: num 0
# $ Flowdir_max  : num 128
# $ Flowdir_min  : num 1
# $ TPI_max      : num 121
# $ TPI_min      : num -134
# $ TRI_max      : num 147
# $ TRI_min      : num 0

#Uncomment the following line and install the package if not already installed
#install.packages("purrr")
#Load required package 'purrr' (in addition to 'dplyr')
library(purrr)
# Ignore warning:
# Warning message:
#   In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object

# Define variables of interest
vars <- c("Elevation", "Aspect", "Slope", "Roughness", "Flowdir", "TPI", "TRI")

#Create the following function:
compare_stats <- function(class_df, global_stats) {
  class_stats <- class_df %>%
    summarise(across(all_of(vars),
                     list(max = ~max(., na.rm = TRUE),
                          min = ~min(., na.rm = TRUE))))
              
              # Create a tidy long-format result
              tibble(
                Class = unique(class_df$Name)[1],
                map_dfr(vars, ~ {
                  tibble(
                    Variable = .x,
                    max_diff = global_stats[[paste0(.x, "_max")]] - class_stats[[paste0(.x, "_max")]],
                    min_diff = global_stats[[paste0(.x, "_min")]] - class_stats[[paste0(.x, "_min")]],
                    range = global_stats[[paste0(.x, "_max")]] - global_stats[[paste0(.x, "_min")]],
                    global_max = global_stats[[paste0(.x, "_max")]], 
                    global_min = global_stats[[paste0(.x, "_min")]]
                  )
                })
              )
}

#The following code snippet uses map_dfr() to apply compare_stats() to each 
#element of split_df_list (with global_stats as additional argument)
#The results are row-bound into a data frame (Un-nesting the results is not necessary since the columns are not nested)
diff_results <- map_dfr(split_df_list, compare_stats, global_stats) 

----------OPTIONAL (START) --------------

class(diff_results)
str(diff_results)
#Manually test if this correct:
#Highest elevation in the raster
elev@pntr[["range_max"]]
# [1] 5186
#Highest elevation among the training data points for the first class in the 
#'split_df_list' object (i.e. AGR)
max(split_df_list[[1]]$Elevation)
# [1] 3738

#Their difference:
elev@pntr[["range_max"]] - max(split_df_list[[1]]$Elevation)
#5816-3738 =
# [1] 1448

# The value in diff_results (under 'max_diff' for AGR) is 1.448000e+03 which is 
#the same. So, it's correct

----------OPTIONAL (END) --------------

#This is in itself is difficult to interpret. So, express the differences in
#terms of the proportion of the range of each class:

#(OPTIONAL) Check the class of 'diff_results'
class(diff_results)
#[1] "tbl_df"     "tbl"        "data.frame"

#Add the percentage of proportions as two more columns in the 'diff_results' object
diff_results <- diff_results %>% mutate(max_diff_perc = (max_diff/range)*100,
                                        min_diff_perc = (min_diff/range)*100)

#Find the significant differences (with 15% taken as the threshold after some trial and error testing):
diff_results <- diff_results %>% 
                  mutate(sig_max_diff =
                           case_when(max_diff_perc > 15 ~ "sig",
                                     max_diff_perc < 15 ~ "insig"),
                         sig_min_diff =
                           case_when(min_diff_perc < -15 ~ "sig",
                                     min_diff_perc > -15 ~ "insig"))

#Find the maximum and minimum values for each class:
diff_results <- diff_results %>% 
    mutate(class_max =
           case_when(sig_max_diff == "sig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_max,
                     sig_max_diff == "sig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_max,
                     sig_max_diff == "sig" & Variable == "Slope" 
                     ~ global_stats$Slope_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Slope" 
                     ~ global_stats$Slope_max,
                     sig_max_diff == "sig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_max,
                     sig_max_diff == "sig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_max,
                     sig_max_diff == "sig" & Variable == "TPI" 
                     ~ global_stats$TPI_max - max_diff,
                     sig_max_diff == "insig" & Variable == "TPI" 
                     ~ global_stats$TPI_max,
                     sig_max_diff == "sig" & Variable == "TRI" 
                     ~ global_stats$TRI_max - max_diff,
                     sig_max_diff == "insig" & Variable == "TRI" 
                     ~ global_stats$TRI_max),

    
         class_min =
         case_when(sig_min_diff == "sig" & Variable == "Elevation" 
                  ~ global_stats$Elevation_min - min_diff,
                  sig_min_diff == "insig" & Variable == "Elevation" 
                  ~ global_stats$Elevation_min,
                  sig_min_diff == "sig" & Variable == "Aspect" 
                  ~ global_stats$Aspect_min - min_diff,
                  sig_min_diff == "insig" & Variable == "Aspect" 
                  ~ global_stats$Aspect_min,
                  sig_min_diff == "sig" & Variable == "Slope" 
                  ~ global_stats$Slope_min - min_diff,
                  sig_min_diff == "insig" & Variable == "Slope" 
                  ~ global_stats$Slope_min,
                  sig_min_diff == "sig" & Variable == "Roughness" 
                  ~ global_stats$Roughness_min - min_diff,
                  sig_min_diff == "insig" & Variable == "Roughness" 
                  ~ global_stats$Roughness_min,
                  sig_min_diff == "sig" & Variable == "Flowdir" 
                  ~ global_stats$Flowdir_min - min_diff,
                  sig_min_diff == "insig" & Variable == "Flowdir" 
                  ~ global_stats$Flowdir_min,
                  sig_min_diff == "sig" & Variable == "TPI" 
                  ~ global_stats$TPI_min - min_diff,
                  sig_min_diff == "insig" & Variable == "TPI" 
                  ~ global_stats$TPI_min,
                  sig_min_diff == "sig" & Variable == "TRI" 
                  ~ global_stats$TRI_min - min_diff,
                  sig_min_diff == "insig" & Variable == "TRI" 
                  ~ global_stats$TRI_min))
                  
#Save as csv
write.csv(diff_results,"diff_results.csv")     

----------OPTIONAL (START) --------------

#See the arguments for the function mask in the raster package:
?raster::mask
        
slp_r <- raster(slp)        

#Mask the values to those of the first class (AGR) (values taken from the 'diff_results'
#object) from the slope raster for the entire Siang Valley:
slp_masked <- mask(slp_r, 
                   mask = slp_r > 0 & slp_r < 54.15373, 
                   maskvalue = 0)

#Check if it worked:
#max
slp_masked@data@min
# [1] 3.180555e-15
#That is close to zero
#min
slp_masked@data@max
# [1] 54.15372 
#exact value that was added

----------OPTIONAL (END) --------------


#Select, mask and intersect the variables for each class (using the 'terra', 'dplyr' and 'purrr' packages). A function is created for the same:
process_class_rasters <- function(class_name, diff_data, rasters) {
  # Filter data for the current class
  class_data <- diff_data %>% filter(Class == class_name)
  
  # Initialize list to store processed rasters
  processed_rasters <- list()
  
  # Process each variable for the class
  for (i in 1:nrow(class_data)) {
    row <- class_data[i, ]
    
    # Skip if both sig flags are insignificant
    if (row$sig_max_diff == "insig" && row$sig_min_diff == "insig") next
    
    # Get the corresponding raster
    raster_name <- case_when(
      row$Variable == "Elevation" ~ "elev",
      row$Variable == "Aspect" ~ "asp",
      row$Variable == "Slope" ~ "slp",
      row$Variable == "Roughness" ~ "rough",
      row$Variable == "Flowdir" ~ "fldr",
      row$Variable == "TPI" ~ "cTPI",
      row$Variable == "TRI" ~ "cTRI",
      TRUE ~ NA_character_
    )
    
    if (is.na(raster_name)) next
    
    # Get the raster
    r <- rasters[[raster_name]]
    
    # Create mask based on significance flags
    if (row$sig_max_diff == "sig" && row$sig_min_diff == "sig") {
      # Both significant - mask outside class range
      masked_r <- clamp(r, lower = row$class_min, upper = row$class_max, values = FALSE)
    } else if (row$sig_max_diff == "sig") {
      # Only max significant - mask above class_max
      masked_r <- clamp(r, upper = row$class_max, values = FALSE)
    } else if (row$sig_min_diff == "sig") {
      # Only min significant - mask below class_min
      masked_r <- clamp(r, lower = row$class_min, values = FALSE)
    } else {
      # Neither significant (shouldn't happen due to earlier check)
      next
    }
    
    # Add to processed list
    processed_rasters[[raster_name]] <- masked_r
  }
  
  # If no rasters were selected, return NULL
  if (length(processed_rasters) == 0) return(NULL)
  
  # Intersect all processed rasters
  # First convert list to SpatRaster with multiple layers
  raster_stack <- rast(processed_rasters)
  
  # Create intersection (values will be NA where any layer is NA)
  intersected_raster <- app(raster_stack, fun = function(x) if (all(!is.na(x))) 1 else NA)
  
  # Set the name
  names(intersected_raster) <- class_name
  
  return(intersected_raster)
}

# The rasters should be in a named list like this:
rasters_list <- list(
  elev = elev,
  asp = asp,
  slp = slp,
  rough = rough,
  fldr = fldr,
  cTPI = cTPI,
  cTRI = cTRI
)

# Get unique classes
unique_classes <- unique(diff_results$Class)

# Process all classes (it took around 35 minutes)
result_rasters <- map(setNames(unique_classes, unique_classes), 
                      ~process_class_rasters(.x, diff_results, rasters_list))

# Remove NULL entries (classes with no significant variables)
result_rasters <- compact(result_rasters)

----------OPTIONAL (START) --------------

#See the structure of the results_raster
str(result_rasters)
#See the plots:
plot(result_rasters$WRC)

#Filter to wet rice cultivation
wrc <- result_df %>% filter(Name == "WRC")

points(wrc[, 2:3], pch = 16, col = "red", cex = 0.6)  
# X and Y columns only

head(result_df)

# Convert SpatRaster to a data frame for ggplot
wrc_df <- as.data.frame(result_rasters$WRC, xy = TRUE)

# Reproject shp to WGS84 (longlat)
shp_wgs84 <- st_transform(shp, crs = "+proj=longlat +datum=WGS84")

p <- ggplot() +
  geom_raster(data = wrc_df, aes(x = x, y = y, fill = WRC), show.legend = FALSE) +
  geom_sf(data = shp_wgs84, fill = NA, color = "black", linewidth = 0.4) +  # Overlay boundary
  geom_point(data = wrc, aes(x = Longitude, y = Latitude), color = "red", size = 0.5,
             show.legend = NA) +
  scale_fill_viridis_c(na.value = "transparent") +  # Adjust color scale
  labs(title = "Collected WRC locations on WRC probability landscape",
         x = "Longitude",
         y = "Latitude")+
  theme_light(base_size = 8)

ggsave("wrc_plot.png", p, width = 1200, height = 1400, units = "px", dpi = 300, 
       scale = 1)
       
#remove the unnecessary objects now:
rm(wrc_df, wrc)
       
```
Output:

![enter image description here](https://i.ibb.co/s9s9DS1M/wrc-plot.png =50%x)

```
#Putting it in a loop to get all the plots (using ggplot2, sf, terra, dplyr, and purrr)

# Get unique class names from the data
class_names <- unique(result_df$Name)

# Reproject shp once (outside loop for efficiency)
shp_wgs84 <- st_transform(shp, crs = "+proj=longlat +datum=WGS84")

#loop
walk(class_names, ~{
  class_data <- result_df %>% filter(Name == .x)
  
  if (!is.null(result_rasters[[.x]])) {
    class_raster_df <- as.data.frame(result_rasters[[.x]], xy = TRUE) %>% 
      rename(value = 3)  # Rename third column to "value"
    
    p <- ggplot() +
      # Use geom_tile() for irregular grids
      geom_tile(data = class_raster_df, 
                aes(x = x, y = y, fill = value), 
                show.legend = FALSE) +
      #Add coord_sf() before geom_sf()
      coord_sf(crs = st_crs(shp_wgs84)$wkt) +  
      geom_sf(data = shp_wgs84, fill = NA, 
              color = "black", linewidth = 0.4) +
      geom_point(data = class_data, 
                 aes(x = Longitude, y = Latitude), 
                 color = "red", size = 0.5) +
      scale_fill_viridis_c(na.value = "transparent") +
      labs(title = paste("Collected", .x, "locations on probability landscape"),
           x = "Longitude",
           y = "Latitude") +
      theme_light(base_size = 8)
    
    ggsave(
      filename = paste0(tolower(.x), "_plot.png"),
      plot = p,
      width = 6, 
      height = 7,
      units = "in",
      dpi = 300
    )
  }
})
----------OPTIONAL (END) --------------
```
Output:

You can ignore these messages:
```
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
Coordinate system already present. Adding new coordinate system, which will replace the existing one.
```
The probability landscape images produced (with respective training data for those classes as red dots):

![enter image description here][23]
![enter image description here][24]
![enter image description here][25]
![enter image description here][26]
![enter image description here][27]
![enter image description here][28]

```
rm(slp, slp_masked)

#Change working directory to the folder containing the rasters to be clipped: 
setwd("D:/GIS/LULC-SIANG/Individual output bands")

----------OPTIONAL (START) --------------

#Load the virtual raster layer for water:
wa <- raster("WA.tif")
wa

# class      : RasterLayer 
# dimensions : 19529, 16052, 313479508  (nrow, ncol, ncell)
# resolution : 10, 10  (x, y)
# extent     : 5340620, 5501140, 4458450, 4653740  (xmin, xmax, ymin, ymax)
# crs        : +proj=lcc +lat_0=24 +lon_0=80 +lat_1=12.472955 +lat_2=35.1728044444444 +x_0=4000000 +y_0=4000000 +datum=WGS84 +units=m +no_defs 
# source     : WA.tif 
# names      : WA 
# values     : 0, 1  (min, max)

# Convert 'wa' (RasterLayer) to SpatRaster
wa <- rast(wa)

#Since the projections are different, they need to be reprojected:

# Get CRS of 'wa' as a PROJ-string
wa_crs_string <- as.character(crs(wa))

# Reproject result_rasters$WA to match 'wa'
wa_lcc <- project(result_rasters$WA, wa_crs_string, method = "near", threads = 4)

# Check frequency of values in wa_lcc
freq(wa_lcc)

# Or count cells with value 1
global(wa_lcc == 1, "sum", na.rm = TRUE)

#The extents of wa and wa_lcc don't perfectly align. So, that has to be fixed: 

# Resample wa_lcc to match wa's extent and resolution
wa_lcc_resam <- resample(wa_lcc, wa, method = "near", threads = 4)

# Crop wa to wa_lcc's extent first
wa_crop_ext <- crop(wa, ext(wa_lcc))

freq(wa_crop_ext)

# Using resampled mask
wa_cropped <- mask(wa_crop_ext, 
                   mask = wa_lcc_resam,
                   maskvalues = c(NA,0))  # Exclude NA and 0
# Plot
plot(wa_cropped)

#Change na values to zeroes
raster_noNA <- wa_cropped
raster_noNA[is.na(raster_noNA)] <- 0  # Replace NAs with 0

#Save
writeRaster(
  raster_noNA,
  filename = "output_raster_zeros.tif", 
  datatype = "INT2S",                   # Use "FLT4S" for floating-point
  NAflag = -9999,
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE                      # Overwrite if file exists
)

# #Save the raster (float type takes up more space):
# writeRaster(
#   wa_cropped,
#   filename = "wa_crp.tif",
#   datatype = "FLT4S",    # Float 32-bit (other options: INT2S, INT4S, etc.)
#   NAflag = -9999,        # Value for missing data
#   gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
#   overwrite = TRUE
# )

rm(wa,wa_crop_ext,wa_cropped,wa_lcc,wa_lcc_resam)

#Load the virtual raster layer for dense canopy:
tf <- raster("TF.tif")
tf

# class      : RasterLayer 
# dimensions : 19529, 16052, 313479508  (nrow, ncol, ncell)
# resolution : 10, 10  (x, y)
# extent     : 5340620, 5501140, 4458450, 4653740  (xmin, xmax, ymin, ymax)
# crs        : +proj=lcc +lat_0=24 +lon_0=80 +lat_1=12.472955 +lat_2=35.1728044444444 +x_0=4000000 +y_0=4000000 +datum=WGS84 +units=m +no_defs 
# source     : TF.tif 
# names      : TF 
# values     : 0, 1  (min, max)

# Convert 'tf' (RasterLayer) to SpatRaster
tf <- rast(tf)

#Since the projections are different, they need to be reprojected:

# Get CRS of 'wa' as a PROJ-string
tf_crs_string <- as.character(crs(tf))

# Reproject result_rasters$WA to match 'wa'
tf_lcc <- project(result_rasters$TF, tf_crs_string, method = "near", threads = 4)

# Check frequency of values in wa_lcc
freq(tf_lcc)

# Or count cells with value 1
global(tf_lcc == 1, "sum", na.rm = TRUE)

#The extents of tf and tf_lcc don't perfectly align.So, that has to be fixed: 

# Resample tf_lcc to match tf's extent and resolution
tf_lcc_resam <- resample(tf_lcc, tf, method = "near", threads = 4)

# Crop tf to tf_lcc's extent first
tf_crop_ext <- crop(tf, ext(tf_lcc))

freq(tf_crop_ext)

# Using resampled mask
tf_cropped <- mask(tf_crop_ext, 
                   mask = tf_lcc_resam,
                   maskvalues = c(NA,0))  # Exclude NA and 0
# Plot
plot(tf_cropped)

#Change na values to zeroes
raster_noNA <- tf_cropped
raster_noNA[is.na(raster_noNA)] <- 0  # Replace NAs with 0

#Save
writeRaster(
  raster_noNA,
  filename = "tf_crop.tif", 
  datatype = "INT2S",                   # Use "FLT4S" for floating-point
  NAflag = -9999,
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE                      # Overwrite if file exists
)
#Load the virtual raster layer for dense canopy:
tf <- raster("TF.tif")
tf

# class      : RasterLayer 
# dimensions : 19529, 16052, 313479508  (nrow, ncol, ncell)
# resolution : 10, 10  (x, y)
# extent     : 5340620, 5501140, 4458450, 4653740  (xmin, xmax, ymin, ymax)
# crs        : +proj=lcc +lat_0=24 +lon_0=80 +lat_1=12.472955 +lat_2=35.1728044444444 +x_0=4000000 +y_0=4000000 +datum=WGS84 +units=m +no_defs 
# source     : TF.tif 
# names      : TF 
# values     : 0, 1  (min, max)

# Convert 'tf' (RasterLayer) to SpatRaster
tf <- rast(tf)

#Since the projections are different, they need to be reprojected:

# Get CRS of 'wa' as a PROJ-string
tf_crs_string <- as.character(crs(tf))

# Reproject result_rasters$WA to match 'wa'
tf_lcc <- project(result_rasters$TF, tf_crs_string, method = "near", threads = 4)

# Check frequency of values in wa_lcc
freq(tf_lcc)

# Or count cells with value 1
global(tf_lcc == 1, "sum", na.rm = TRUE)

#The extents of tf and tf_lcc don't perfectly align. So, that has to be fixed: 

# Resample tf_lcc to match tf's extent and resolution
tf_lcc_resam <- resample(tf_lcc, tf, method = "near", threads = 4)

# Crop tf to tf_lcc's extent first
tf_crop_ext <- crop(tf, ext(tf_lcc))

freq(tf_crop_ext)

# Using resampled mask
tf_cropped <- mask(tf_crop_ext, 
                   mask = tf_lcc_resam,
                   maskvalues = c(NA,0))  # Exclude NA and 0
# Plot
plot(tf_cropped)

#Change na values to zeroes
raster_noNA <- tf_cropped
raster_noNA[is.na(raster_noNA)] <- 0  # Replace NAs with 0

#Save
writeRaster(
  raster_noNA,
  filename = "tf_crop.tif", 
  datatype = "INT2S",                   # Use "FLT4S" for floating-point
  NAflag = -9999,
  gdal=c("COMPRESS=DEFLATE", "TFW=YES"),  # Compression for GeoTIFF
  overwrite = TRUE                      # Overwrite if file exists
)

rm(tf,tf_crop_ext,tf_cropped,tf_lcc,tf_lcc_resam)

----------OPTIONAL (END) --------------

#####For batch processing of misclassified pixel correction using a for-loop####

In addition to the package 'terra', 'stringr' is needed:
#Uncomment the following line and install the package if not already installed
#install.packages("stringr")
library(stringr)

getwd()
# Set up directories and parameters
input_dir <- getwd()  # Directory containing your capital-letter TIFFs

#The processed files are saved in the following folder:
ifelse(!dir.exists(paste0(getwd(),"/processed")),
       dir.create(paste0(getwd(),"/processed")),
       "Directory Exists")
#Gives the message "TRUE" if directory does not exist and it is created. If directory
#exist, gives the message "processed"
crs_template <- crs(rast("OF.tif"))    # CRS to match (using OF.tif as reference)
mask_values <- c(NA, 0)                # Values to mask out
threads <- 4                           # Number of threads for parallel processing (change as per your system specifications)

#Get list of all capital-letter TIFF files
tif_files <- list.files(input_dir, pattern = "^[A-Z]+\\.tif$", full.names = TRUE)

# [1] "D:/GIS/LULC-SIANG/Individual output bands/AGR.tif"
# [2] "D:/GIS/LULC-SIANG/Individual output bands/AJ.tif" 
# [3] "D:/GIS/LULC-SIANG/Individual output bands/BU.tif" 
# [4] "D:/GIS/LULC-SIANG/Individual output bands/CC.tif" 
# [5] "D:/GIS/LULC-SIANG/Individual output bands/MGR.tif"
# [6] "D:/GIS/LULC-SIANG/Individual output bands/OF.tif" 
# [7] "D:/GIS/LULC-SIANG/Individual output bands/SH.tif" 
# [8] "D:/GIS/LULC-SIANG/Individual output bands/SN.tif" 
# [9] "D:/GIS/LULC-SIANG/Individual output bands/SS.tif" 
# [10] "D:/GIS/LULC-SIANG/Individual output bands/WRC.tif"

#Process each file
for (tif_file in tif_files) {
  # Extract base name (e.g., "TF" from "TF.tif")
  base_name <- tools::file_path_sans_ext(basename(tif_file))
  
  cat("Processing", base_name, "...\n")
  
  tryCatch({
    # Load and convert raster
    r <- rast(tif_file)
    
    # Reproject mask to match raster's CRS
    mask_reproj <- project(result_rasters[[base_name]], crs(r), method = "near", threads = threads)
    
    # Resample mask to match raster's resolution
    mask_resam <- resample(mask_reproj, r, method = "near", threads = threads)
    
    # Crop and mask
    r_cropped <- mask(crop(r, ext(mask_resam)), 
                      mask = mask_resam,
                      maskvalues = mask_values)
    
    # Replace NAs with 0
    r_cropped[is.na(r_cropped)] <- 0
    
    # Save output
    output_file <- file.path(output_dir, paste0(base_name, "_processed.tif"))
    writeRaster(
      r_cropped,
      filename = output_file,
      datatype = "INT2S",
      NAflag = -9999,
      gdal = c("COMPRESS=DEFLATE", "TFW=YES"),
      overwrite = TRUE
    )
    
    cat("Successfully processed", base_name, "\n")
  }, error = function(e) {
    cat("Error processing", base_name, ":", e$message, "\n")
  })
}    

```

## Workflow 2 - Minimalist and optimised

```
#Set the working directory:
#ctrl+Shift+H or setwd("D:/GIS/LULC-SIANG/classified_imagery")

#Uncomment (remove #) the following line and Install the packages 'raster' and 
#'sp' if not already installed. Note that you may have to install or update some
#dependencies if the installation is not working. Check the errors/warnings. 
#install.packages(c("raster","sf"))

#Load the 'raster' and 'sf' package:
library(raster)
library(sf)

#SKIP THE NEXT THREE STEP STEPS IF YOU ARE STARTING WITH A KML FILE

# Add the  kmz file containing the training data to the "classified_imagery" folder
#list the kmz files in the folder (should be just the one file with the training data)
kmz <- list.files(pattern="*.kmz", full.names=FALSE)

# Create temporary directory
temp_dir <- tempdir()

# Unzip KMZ (this will extract the KML file inside
unzip(kmz, exdir = temp_dir)

# Find the extracted KML file (or just the kml file if you're starting directly from kml)
kml_file <- list.files(temp_dir, pattern = "\\.kml$", full.names = TRUE)

# Read the KML file with sf
data <- st_read(kml_file)

Output in Windows: 
# Reading layer `2024_updated' from data source 
#   `C:\Users\GIS\AppData\Local\Temp\RtmpQPSSTT\doc.kml' using driver `KML'
# Simple feature collection with 2358 features and 2 fields
# Geometry type: POINT
# Dimension:     XYZ
# Bounding box:  xmin: 93.99069 ymin: 27.56451 xmax: 95.56589 ymax: 29.33588
# z_range:       zmin: 0 zmax: 0
# Geodetic CRS:  WGS 84

# Extract all raster values at once using terra 

#Load the 'terra' package. We will use sf and dplyr too
library(terra)
library(dplyr)

# Get coordinates and convert to terra vect
coords_vect <- vect(data)

#Change working directory to where the DEM to be used is located (or else, move 
#the DEM to the current working directory): setwd("D:/GIS/LULC-SIANG/DEM")

# Load DEM using terra directly (skip raster package)
dem <- rast("alos.vrt")

# Extract elevation
elev_vals <- terra::extract(dem, coords_vect)[, 2]  # Second column has values

#Ignore these warnings:
# Warning messages:
#   1: In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object
# 2: In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object
# 3: In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object
# 4: In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object
# 5: In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object

# Create result dataframe
result_df <- data.frame(
  Name = data$Name,
  Longitude = st_coordinates(data)[, 1],
  Latitude = st_coordinates(data)[, 2],
  Elevation = elev_vals
)

# Calculate and extract all terrain indices in one go
terrain_params <- c('aspect', 'slope', 'TPI', 'TRI', 'roughness', 'flowdir')

# Create and extract all values in single pass (took around 10-20 s)
all_terrain_vals <- do.call(cbind, lapply(terrain_params, function(param) {
  cat("Processing", param, "...\n")
  #Create the DEM objects like slope, aspect, roughness etc
  terrain_raster <- terrain(dem, v = param, 
                            unit = ifelse(param %in% c('aspect', 'slope'), 'degrees', 'radians'),
                            neighbors = 8)
  #Neighbours = 8 best for rough surfaces Horn (1981) like Siang 
  #Extract the values at each of the training data coordinates
  terra::extract(terrain_raster, coords_vect)[, 2]
}))

#Rename the column names of 'all_terrain_vals'
colnames(all_terrain_vals) <- c("Aspect", "Slope", "TPI", "TRI", "Roughness", "Flowdir")
#Add the slope, aspect, TPI, TRI, roughness and flowdir information for the corresponding 
#coordinates in result_df
result_df <- bind_cols(result_df, all_terrain_vals)

# Split the dataframe by the 'Name' column to get the different classes (to be used
#in a later step):
split_df_list <- result_df %>% group_split(Name)

# Mask all rasters at once
shp_vect <- vect(read_sf("study_area/study_area.shp"))

# Check CRS and project shapefile to match DEM CRS 
if (!same.crs(dem, shp_vect)) {
  cat("CRS mismatch detected. Projecting shapefile to match DEM CRS...\n")
  cat("DEM CRS:", crs(dem, describe = TRUE)$name, "\n")
  cat("Shapefile CRS:", crs(shp_vect, describe = TRUE)$name, "\n")
  
  shp_vect_projected <- project(shp_vect, dem)
  cat("Shapefile reprojected to match DEM CRS\n")
} else {
  cat("CRS match confirmed - no reprojection needed\n")
  shp_vect_projected <- shp_vect
}

# Now mask all rasters (after extracting the relevant feature like aspect if necessary (not necessary for elevation)) using the already-projected shapefile (takes around a minute)
cat("Masking rasters...\n")
#DEM is equivalent to elevation
elev <- mask(dem, shp_vect_projected)
# The terrain functions calculate things like aspect, slope etc before masking
asp <- mask(terrain(dem, v = 'aspect', unit = 'degrees', neighbors = 8), shp_vect_projected)
slp <- mask(terrain(dem, v = 'slope', unit = 'degrees', neighbors = 8), shp_vect_projected)
cTPI <- mask(terrain(dem, v = 'TPI'), shp_vect_projected)
cTRI <- mask(terrain(dem, v = 'TRI'), shp_vect_projected)
rough <- mask(terrain(dem, v = 'roughness'), shp_vect_projected)
fldr <- mask(terrain(dem, v = 'flowdir'), shp_vect_projected)

# Cleanup
rm(dem, all_terrain_vals, elev_vals, coords_vect, shp_vect)
gc()

#Find the difference between maximum and minimum between different classes and
#combined histograms (for the whole data and not just tne points where the training
#data lies). These global_stats can be extracted through the following:

global_stats <- as.data.frame(cbind(
  Elevation_max = elev@pntr[["range_max"]],
  Elevation_min = elev@pntr[["range_min"]],
  Aspect_max = asp@pntr[["range_max"]],
  Aspect_min = asp@pntr[["range_min"]],
  Slope_max = slp@pntr[["range_max"]],
  Slope_min = slp@pntr[["range_min"]],
  Roughness_max = rough@pntr[["range_max"]],
  Roughness_min = rough@pntr[["range_min"]],
  Flowdir_max = fldr@pntr[["range_max"]],
  Flowdir_min = fldr@pntr[["range_min"]],
  TPI_max = cTPI@pntr[["range_max"]],
  TPI_min = cTPI@pntr[["range_min"]],
  TRI_max = cTRI@pntr[["range_max"]],
  TRI_min = cTRI@pntr[["range_min"]]
))

#Note that the word 'pntr' may need to be changed to 'cpp' if using an earlier
#version of the terra package(?) (the above operation will throw this error otherwise:
# Error in h(simpleError(msg, call)) : error in evaluating the argument 'x' in 
#selecting a method for function 'as.data.frame': no slot of name "cpp" for this 
#object of class "SpatRaster"
#You can check by looking at one of the above objects. For example, check under 
#which main heading "range_max" and "range_min" of the object 'elev' is under:
View(elev)

#Load required package 'purrr' (in addition to 'dplyr')
library(purrr)
# Ignore warning:
# Warning message:
#   In class(object) <- "environment" :
#   Setting class(x) to "environment" sets attribute to NULL; result will no longer be an S4 object

# Define variables of interest
vars <- c("Elevation", "Aspect", "Slope", "Roughness", "Flowdir", "TPI", "TRI")

#Create the following function:
compare_stats <- function(class_df, global_stats) {
  class_stats <- class_df %>%
    summarise(across(all_of(vars),
                     list(max = ~max(., na.rm = TRUE),
                          min = ~min(., na.rm = TRUE))))
  
  # Create a tidy long-format result
  tibble(
    Class = unique(class_df$Name)[1],
    map_dfr(vars, ~ {
      tibble(
        Variable = .x,
        max_diff = global_stats[[paste0(.x, "_max")]] - class_stats[[paste0(.x, "_max")]],
        min_diff = global_stats[[paste0(.x, "_min")]] - class_stats[[paste0(.x, "_min")]],
        range = global_stats[[paste0(.x, "_max")]] - global_stats[[paste0(.x, "_min")]],
        global_max = global_stats[[paste0(.x, "_max")]], 
        global_min = global_stats[[paste0(.x, "_min")]]
      )
    })
  )
}

#The following code snippet uses map_dfr() to apply compare_stats() to each 
#element of split_df_list (with global_stats as additional argument)
#The results are row-bound into a data frame (Un-nesting the results is not 
#necessary since the columns are not nested)
diff_results <- map_dfr(split_df_list, compare_stats, global_stats) 

#This is in itself is difficult to interpret. So, express the differences in
#terms of the proportion of the range of each class:

#Add the percentage of proportions as two more columns in the 'diff_results' object
diff_results <- diff_results %>% mutate(max_diff_perc = (max_diff/range)*100,
                                        min_diff_perc = (min_diff/range)*100)

#Find the significant differences (with >15% and <15% taken as the threshold after 
#some trial and error testing) and add them as two more columns:
diff_results <- diff_results %>% 
  mutate(sig_max_diff =
           case_when(max_diff_perc > 15 ~ "sig",
                     max_diff_perc < 15 ~ "insig"),
         sig_min_diff =
           case_when(min_diff_perc < -15 ~ "sig",
                     min_diff_perc > -15 ~ "insig"))

#Find the maximum and minimum values for each class:
diff_results <- diff_results %>% 
  mutate(class_max =
           case_when(sig_max_diff == "sig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_max,
                     sig_max_diff == "sig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_max,
                     sig_max_diff == "sig" & Variable == "Slope" 
                     ~ global_stats$Slope_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Slope" 
                     ~ global_stats$Slope_max,
                     sig_max_diff == "sig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_max,
                     sig_max_diff == "sig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_max - max_diff,
                     sig_max_diff == "insig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_max,
                     sig_max_diff == "sig" & Variable == "TPI" 
                     ~ global_stats$TPI_max - max_diff,
                     sig_max_diff == "insig" & Variable == "TPI" 
                     ~ global_stats$TPI_max,
                     sig_max_diff == "sig" & Variable == "TRI" 
                     ~ global_stats$TRI_max - max_diff,
                     sig_max_diff == "insig" & Variable == "TRI" 
                     ~ global_stats$TRI_max),
         
         
         class_min =
           case_when(sig_min_diff == "sig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_min - min_diff,
                     sig_min_diff == "insig" & Variable == "Elevation" 
                     ~ global_stats$Elevation_min,
                     sig_min_diff == "sig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_min - min_diff,
                     sig_min_diff == "insig" & Variable == "Aspect" 
                     ~ global_stats$Aspect_min,
                     sig_min_diff == "sig" & Variable == "Slope" 
                     ~ global_stats$Slope_min - min_diff,
                     sig_min_diff == "insig" & Variable == "Slope" 
                     ~ global_stats$Slope_min,
                     sig_min_diff == "sig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_min - min_diff,
                     sig_min_diff == "insig" & Variable == "Roughness" 
                     ~ global_stats$Roughness_min,
                     sig_min_diff == "sig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_min - min_diff,
                     sig_min_diff == "insig" & Variable == "Flowdir" 
                     ~ global_stats$Flowdir_min,
                     sig_min_diff == "sig" & Variable == "TPI" 
                     ~ global_stats$TPI_min - min_diff,
                     sig_min_diff == "insig" & Variable == "TPI" 
                     ~ global_stats$TPI_min,
                     sig_min_diff == "sig" & Variable == "TRI" 
                     ~ global_stats$TRI_min - min_diff,
                     sig_min_diff == "insig" & Variable == "TRI" 
                     ~ global_stats$TRI_min))

#Save as csv
write.csv(diff_results,"diff_results.csv")  

#Select, mask and intersect the variables for each class (using the 'terra', 
#'dplyr' and 'purrr' packages). A function is created for the same:
process_class_rasters <- function(class_name, diff_data, rasters) {
  # Filter data for the current class
  class_data <- diff_data %>% filter(Class == class_name)
  
  # Initialize list to store processed rasters
  processed_rasters <- list()
  
  # Process each variable for the class
  for (i in 1:nrow(class_data)) {
    row <- class_data[i, ]
    
    # Skip if both sig flags are insignificant
    if (row$sig_max_diff == "insig" && row$sig_min_diff == "insig") next
    
    # Get the corresponding raster
    raster_name <- case_when(
      row$Variable == "Elevation" ~ "elev",
      row$Variable == "Aspect" ~ "asp",
      row$Variable == "Slope" ~ "slp",
      row$Variable == "Roughness" ~ "rough",
      row$Variable == "Flowdir" ~ "fldr",
      row$Variable == "TPI" ~ "cTPI",
      row$Variable == "TRI" ~ "cTRI",
      TRUE ~ NA_character_
    )
    
    if (is.na(raster_name)) next
    
    # Get the raster
    r <- rasters[[raster_name]]
    
    # Create mask based on significance flags
    if (row$sig_max_diff == "sig" && row$sig_min_diff == "sig") {
      # Both significant - mask outside class range
      masked_r <- clamp(r, lower = row$class_min, upper = row$class_max, values = FALSE)
    } else if (row$sig_max_diff == "sig") {
      # Only max significant - mask above class_max
      masked_r <- clamp(r, upper = row$class_max, values = FALSE)
    } else if (row$sig_min_diff == "sig") {
      # Only min significant - mask below class_min
      masked_r <- clamp(r, lower = row$class_min, values = FALSE)
    } else {
      # Neither significant (shouldn't happen due to earlier check)
      next
    }
    
    # Add to processed list
    processed_rasters[[raster_name]] <- masked_r
  }
  
  # If no rasters were selected, return NULL
  if (length(processed_rasters) == 0) return(NULL)
  
  # Intersect all processed rasters
  # First convert list to SpatRaster with multiple layers
  raster_stack <- rast(processed_rasters)
  
  # Create intersection (values will be NA where any layer is NA)
  intersected_raster <- app(raster_stack, fun = function(x) if (all(!is.na(x))) 1 else NA)
  
  # Set the name
  names(intersected_raster) <- class_name
  
  return(intersected_raster)
}

# The rasters should be in a named list like this:
rasters_list <- list(
  elev = elev,
  asp = asp,
  slp = slp,
  rough = rough,
  fldr = fldr,
  cTPI = cTPI,
  cTRI = cTRI
)

# Get unique classes
unique_classes <- unique(diff_results$Class)

# Process all classes (it took around 35 minutes)
result_rasters <- map(setNames(unique_classes, unique_classes), 
                      ~process_class_rasters(.x, diff_results, rasters_list))

# Remove NULL entries (classes with no significant variables)
result_rasters <- compact(result_rasters)

#The next step is the beginning of bulk processing of all the models in the device. 

#First, set the working directory. This directory should contain all the folders containing the models. For safety, you can keep it as the highest directory possible - home directory or D drive (if all the folders are in D drive):
setwd("D:/GIS")

#The function that does post-processing at once requires a csv file that contains several model details including the name of the model and and the directory path of model. It will look like the following:
```

```
   sl_no satellite             model_name BA_as_TF SH_as_TF BA.SH_as_TF  directory
1      1  Sentinel  dir_sent_RFC_seven_ml        1        0           0  D:\\GIS\\force
2      2  Sentinel  dir_sent_RFC_eight_ml        1        0           0  D:\\GIS\\force
3      3  Sentinel   dir_sent_RFC_nine_ml        0        0           1  D:\\GIS\\force
4      4  Landsat     dir_land_RFC_ten_ml        0        0           1  D:\\GIS\\force2
5      5  Landsat  dir_land_RFC_eleven_ml        0        0           0  D:\\GIS\\force2
6      6  Sentinel    dir_ml_sent_RFC_pbc        0        0           0 D:\\GIS\\force3
7      7  Sentinel    dir_ml_sent_RFC_one        0        0           0 D:\\GIS\\force3
8      8  Sentinel    dir_ml_sent_SVC_one        0        0           0 D:\\GIS\\force3
9      9  Landsat    dir_ml_land_RFC_four        0        1           0 D:\\GIS\\force2
10    10  Sentinel    dir_ml_sent_SVC_two        0        1           0 D:\\GIS\\force3
11    11  Sentinel   dir_ml_sent_RFC_five        0        1           0 D:\\GIS\\force3
12    12  Sentinel  dir_ml_sent_SVC_three        0        1           0 D:\\GIS\\force3
13    13  Sentinel    dir_ml_sent_RFC_six        0        1           0 /home/GIS/force2
14    14  Sentinel   dir_ml_sent_SVC_four        0        1           0 /home/GIS/force2
15    15  Sentinel   dir_ml_sent_RFC_nine        0        1           0 /home/GIS/force2
```
```
# Load the csv containing model details
mod_det <- read.csv("force/model_details5.csv")

library(terra)
library(stringr)
library(sf)

# Pre-compute ALL shared resources (class_mapping and reprojection for the shapefile to match the MLP files) ONCE before bulk automated processing
cat("Pre-computing shared resources...\n")

# Pre-compute class mapping (constant)
class_mapping <- c(
  "MODEL_CLASS_001" = "TF",
  "MODEL_CLASS_002" = "SN", 
  "MODEL_CLASS_003" = "OF",
  "MODEL_CLASS_004" = "BA",
  "MODEL_CLASS_005" = "CC",
  "MODEL_CLASS_006" = "AJ",
  "MODEL_CLASS_007" = "WRC",
  "MODEL_CLASS_008" = "SH",
  "MODEL_CLASS_009" = "BU",
  "MODEL_CLASS_010" = "AGR",
  "MODEL_CLASS_011" = "MGR",
  "MODEL_CLASS_012" = "WA",
  "MODEL_CLASS_013" = "SS"
)

#The already loaded "shp" will be used in the following loop. Pre-reproject the 
#shapefile ONCE for all models (since all MLPS which will be converted to VRTs will
#have the same CRS - EPSG:7755)
cat("Reprojecting shapefile to EPSG:7755 for all models...\n")
target_crs <- "EPSG:7755"
shp_reprojected <- st_transform(shp, target_crs)
shp_vect <- vect(shp_reprojected)  # Convert to SpatVector for faster masking

cat("Shapefile reprojection completed\n")

# Modified function with better path handling
process_with_vrt <- function(model_name) {
  
  # Find the model info
  model_info <- mod_det[mod_det$model_name == model_name, ]
  
  if (nrow(model_info) == 0) {
    stop(paste("Model", model_name, "not found in mod_det"))
  }
  
  # Use the directory path directly from mod_det
  dir_path <- paste0(model_info$directory,"/",model_name)
  # Clean path separators if needed
  dir_path <- gsub("\\\\", "/", dir_path)
  
  cat("Processing model:", model_name, "\n")
  cat("Directory:", dir_path, "\n")
  
  # Check if directory exists
  if (!dir.exists(dir_path)) {
    warning("Directory does not exist: ", dir_path)
    return(FALSE)
  }
  
  # Create VRT - search in the specific model directory
  mlp_files <- list.files(dir_path, pattern = "PREDICTION_HL_ML_MLP\\.tif$", 
                          recursive = TRUE, full.names = TRUE)
  
  print(paste("Found", length(mlp_files), "PREDICTION_HL_ML_MLP.tif files"))
  
  if (length(mlp_files) == 0) {
    warning("No MLP files found for model: ", model_name, " in ", dir_path)
    return(FALSE)
  }
  
  # Read the first file to get original band names
  first_raster <- rast(mlp_files[1])
  original_band_names <- names(first_raster)
  
  print("Original band names:")
  print(original_band_names)
  
  # Create the virtual raster tile
  cat("Creating VRT from", length(mlp_files), "MLP files...\n")
  vrt_file <- file.path(dir_path, "merged_mosaic.vrt")
  mosaic_vrt <- vrt(mlp_files, vrt_file, overwrite = TRUE)
  
  # Apply original band names to the VRT
  names(mosaic_vrt) <- original_band_names
  
  print("VRT band names after renaming:")
  print(names(mosaic_vrt))
  
  # Vectorized renaming
  current_names <- names(mosaic_vrt)
  new_names <- ifelse(current_names %in% names(class_mapping),
                      class_mapping[current_names],
                      current_names)
  
  names(mosaic_vrt) <- new_names
  
  print("VRT band names after class mapping:")
  print(names(mosaic_vrt))
  
  # Setup output directory - create it within the model's directory
  output_dir <- file.path(dir_path, "processed")
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
    cat("Created directory:", output_dir, "\n")
  } else {
    cat("Directory exists:", output_dir, "\n")
  }
  
  mask_values <- c(NA, 0)
  threads <- 14
  
  # Process each band from the VRT directly
  for (class_name in names(mosaic_vrt)) {
    cat("Processing class:", class_name, "...\n")
    
    tryCatch({
      # Get the input raster from VRT
      r <- mosaic_vrt[[class_name]]
      
      # Check if we have a corresponding result_raster for this class
      if (!class_name %in% names(result_rasters)) {
        cat("Skipping", class_name, "- no corresponding result_raster found\n")
        next
      }
      
      # Get the corresponding mask from result_rasters
      mask_band <- result_rasters[[class_name]]
      
      # Reproject mask to match VRT band's CRS
      mask_reproj <- project(mask_band, crs(r), method = "near", threads = threads)
      
      # Resample mask to match VRT band's resolution
      mask_resam <- resample(mask_reproj, r, method = "near", threads = threads)
      
      # Create a mask where mask_band has valid values
      valid_mask <- !is.na(mask_resam) & mask_resam != 0
      
      # Apply the mask to the VRT band
      r_masked <- r * valid_mask
      
      # Replace NAs with 0
      r_masked[is.na(r_masked)] <- 0
      
      # Clip to shapefile
      r_cropped <- mask(r_masked, shp_vect)
      
      # Check non-zero values
      non_zero_count <- global(!is.na(r_cropped) & r_cropped > 0, "sum", na.rm = TRUE)[1,1]
      cat("Non-zero pixels in", class_name, ":", non_zero_count, "\n")
      
      # Save output
      output_file <- file.path(output_dir, paste0(class_name, "_processed.tif"))
      writeRaster(
        r_cropped,
        filename = output_file,
        datatype = "INT2S",
        NAflag = -9999,
        gdal = c("COMPRESS=DEFLATE", "TFW=YES"),
        overwrite = TRUE
      )
      
      cat("Successfully processed", class_name, "\n")
      
      # Clean up
      rm(r, mask_band, mask_reproj, mask_resam, r_cropped)
      gc()
      
    }, error = function(e) {
      cat("Error processing", class_name, ":", e$message, "\n")
    })
  }
  
  return(TRUE)
}

# Run for all models
for (i in 1:nrow(mod_det)) {
  model_name <- mod_det$model_name[i]
  cat("\n", rep("=", 50), "\n", sep = "")
  cat("Processing model", i, "of", nrow(mod_det), ":", model_name, "\n")
  cat(rep("=", 50), "\n\n", sep = "")
  
  tryCatch({
    success <- process_with_vrt(model_name)
    if (success) {
      cat("✓ Successfully completed", model_name, "\n")
    } else {
      cat("⚠ Completed with warnings:", model_name, "\n")
    }
  }, error = function(e) {
    cat("✗ Failed to process", model_name, ":", e$message, "\n")
  })
}

```




Output:
```
==================================================
Processing model 1 of 5 : dir_sent_RFC_eight_ml 
==================================================

Processing model: dir_sent_RFC_eight_ml 
Directory: D:/Paul_Pop_RS_GIS_files/force/dir_sent_RFC_eight_ml 
[1] "Found 33 PREDICTION_HL_ML_MLP.tif files"
[1] "Original band names:"
 [1] "MODEL_CLASS_001" "MODEL_CLASS_002" "MODEL_CLASS_003" "MODEL_CLASS_005" "MODEL_CLASS_006"
 [6] "MODEL_CLASS_007" "MODEL_CLASS_008" "MODEL_CLASS_009" "MODEL_CLASS_010" "MODEL_CLASS_011"
[11] "MODEL_CLASS_012" "MODEL_CLASS_013"
Creating VRT from 33 MLP files...
[1] "VRT band names after renaming:"
 [1] "MODEL_CLASS_001" "MODEL_CLASS_002" "MODEL_CLASS_003" "MODEL_CLASS_005" "MODEL_CLASS_006"
 [6] "MODEL_CLASS_007" "MODEL_CLASS_008" "MODEL_CLASS_009" "MODEL_CLASS_010" "MODEL_CLASS_011"
[11] "MODEL_CLASS_012" "MODEL_CLASS_013"
[1] "VRT band names after class mapping:"
 [1] "TF"  "SN"  "OF"  "CC"  "AJ"  "WRC" "SH"  "BU"  "AGR" "MGR" "WA"  "SS" 
Reprojecting shapefile to match VRT CRS...
Created directory: D:/Paul_Pop_RS_GIS_files/force/dir_sent_RFC_eight_ml/processed 
Processing class: TF ...
Non-zero pixels in TF : 95668977          
Successfully processed TF 
Processing class: SN ...
Non-zero pixels in SN : 7931184           
Successfully processed SN 
Processing class: OF ...
Non-zero pixels in OF : 1941672           
Successfully processed OF 
Processing class: CC ...
Non-zero pixels in CC : 113400            
Successfully processed CC 
Processing class: AJ ...
Non-zero pixels in AJ : 125361            
Successfully processed AJ 
Processing class: WRC ...
Non-zero pixels in WRC : 1472026          
Successfully processed WRC 
Processing class: SH ...
Non-zero pixels in SH : 19816537          
Successfully processed SH 
Processing class: BU ...
Non-zero pixels in BU : 117037            
Successfully processed BU 
Processing class: AGR ...
Non-zero pixels in AGR : 148663           
Successfully processed AGR 
Processing class: MGR ...
Non-zero pixels in MGR : 1001121          
Successfully processed MGR 
Processing class: WA ...
Non-zero pixels in WA : 1831789           
Successfully processed WA 
Processing class: SS ...
Non-zero pixels in SS : 1429952           
Successfully processed SS 
✓ Successfully completed dir_sent_RFC_eight_ml 
.
.
.
==================================================
Processing model 5 of 5 : dir_ml_sent_RFC_pbc 
==================================================

Processing model: dir_ml_sent_RFC_pbc 
Directory: D:/Paul_Pop_RS_GIS_files/force3/dir_ml_sent_RFC_pbc 
[1] "Found 33 PREDICTION_HL_ML_MLP.tif files"
[1] "Original band names:"
 [1] "MODEL_CLASS_001" "MODEL_CLASS_002" "MODEL_CLASS_003" "MODEL_CLASS_004" "MODEL_CLASS_005"
 [6] "MODEL_CLASS_006" "MODEL_CLASS_007" "MODEL_CLASS_008" "MODEL_CLASS_009" "MODEL_CLASS_010"
[11] "MODEL_CLASS_011" "MODEL_CLASS_012" "MODEL_CLASS_013"
Creating VRT from 33 MLP files...
[1] "VRT band names after renaming:"
 [1] "MODEL_CLASS_001" "MODEL_CLASS_002" "MODEL_CLASS_003" "MODEL_CLASS_004" "MODEL_CLASS_005"
 [6] "MODEL_CLASS_006" "MODEL_CLASS_007" "MODEL_CLASS_008" "MODEL_CLASS_009" "MODEL_CLASS_010"
[11] "MODEL_CLASS_011" "MODEL_CLASS_012" "MODEL_CLASS_013"
[1] "VRT band names after class mapping:"
 [1] "TF"  "SN"  "OF"  "BA"  "CC"  "AJ"  "WRC" "SH"  "BU"  "AGR" "MGR" "WA"  "SS" 
Reprojecting shapefile to match VRT CRS...
Created directory: D:/Paul_Pop_RS_GIS_files/force3/dir_ml_sent_RFC_pbc/processed 
Processing class: TF ...
Non-zero pixels in TF : 43186526          
Successfully processed TF 
Processing class: SN ...
Non-zero pixels in SN : 7582564           
Successfully processed SN 
Processing class: OF ...
Non-zero pixels in OF : 580921            
Successfully processed OF 
Processing class: BA ...
Non-zero pixels in BA : 5740512           
Successfully processed BA 
Processing class: CC ...
Non-zero pixels in CC : 116793            
Successfully processed CC 
Processing class: AJ ...
Non-zero pixels in AJ : 61641             
Successfully processed AJ 
Processing class: WRC ...
Non-zero pixels in WRC : 1059440          
Successfully processed WRC 
Processing class: SH ...
Non-zero pixels in SH : 11728796          
Successfully processed SH 
Processing class: BU ...
Non-zero pixels in BU : 203853            
Successfully processed BU 
Processing class: AGR ...
Non-zero pixels in AGR : 337866           
Successfully processed AGR 
Processing class: MGR ...
Non-zero pixels in MGR : 1034902          
Successfully processed MGR 
Processing class: WA ...
Non-zero pixels in WA : 1729416           
Successfully processed WA 
Processing class: SS ...
Non-zero pixels in SS : 1029785           
Successfully processed SS 
✓ Successfully completed dir_ml_sent_RFC_pbc 
```
For models which are not found in the system or the working directory, we get the following output:

```
==================================================
Processing model 99 of 114 : dir_ml_RFC_25 
==================================================

Processing model: dir_ml_RFC_25 
Directory: /home/GIS/force/dir_ml_RFC_25 
⚠ Completed with warnings: dir_ml_RFC_25 

==================================================
Processing model 100 of 114 : dir_ml_SVC_21 
==================================================

Processing model: dir_ml_SVC_21 
Directory: /home/GIS/force/dir_ml_SVC_21  
⚠ Completed with warnings: dir_ml_SVC_21 
```

  [1]: https://i.ibb.co/8ypdQ8J/distribution-of-training-data.png
  [2]: https://i.ibb.co/d0kdgc3r/aspect.png
  [3]: https://i.ibb.co/0pp7W9zv/slope.png
  [4]: https://i.ibb.co/SXFtfZNR/TPI.png
  [5]: https://i.ibb.co/d4mn0D1w/TRI.png
  [6]: https://i.ibb.co/WWxT270m/roughness.png
  [7]: https://i.ibb.co/rTVHcGj/flowdir.png
  [8]: https://i.ibb.co/9FWpsZN/terrain-histograms.png
  [9]: https://i.ibb.co/ZRXfpZvq/terrain-histograms-alluvial-grasslands.png
  [10]: https://i.ibb.co/VpHNphX6/terrain-histograms-active-jhum.png
  [11]: https://i.ibb.co/kgh7BjwB/terrain-histograms-bamboo.png
  [12]: https://i.ibb.co/4w16YsDn/terrain-histograms-built-up.png
  [13]: https://i.ibb.co/cXx4x41p/terrain-histograms-cash-crops.png
  [14]: https://i.ibb.co/TBJMx1Zt/terrain-histograms-montane-grassland.png
  [15]: https://i.ibb.co/HDsffkqK/terrain-histograms-open-canopy.png
  [16]: https://i.ibb.co/CKJQtHyY/terrain-histograms-shadow.png
  [17]: https://i.ibb.co/zW9XwFTX/terrain-histograms-snow.png
  [18]: https://i.ibb.co/cKt8C4Z5/terrain-histograms-bare-surface.png
  [19]: https://i.ibb.co/j9LbX7DD/terrain-histograms-dense-canopy.png
  [20]: https://i.ibb.co/9Ccg8cp/terrain-histograms-water.png
  [21]: https://i.ibb.co/qMjwd7gt/terrain-histograms-wet-rice-cultivation.png
  [22]: https://i.ibb.co/ZpD0ff10/elevation.png
  [23]: https://i.ibb.co/Z66fW1Qk/AGR-and-AJ.png
  [24]: https://i.ibb.co/k68HphWP/BA-and-BU.png
  [25]: https://i.ibb.co/spnMMgh5/CC-and-MGR.png
  [26]: https://i.ibb.co/nqKt67cs/OF-and-SH.png
  [27]: https://i.ibb.co/NzPpBHC/SN-and-SS.png
  [28]: https://i.ibb.co/6RHBRVzR/TF-and-WA.png
